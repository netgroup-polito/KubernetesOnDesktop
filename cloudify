#!/bin/bash

#Final state machine like
state=0
#Installation path
folder="/opt/Cloudify"
#Quality level for the connection
quality=5
#Compression level
compression=2
#Protocol to be used (default VNC)
protocol="vnc"
#Timeout to wait for the pod creation (expressed in seconds)
timeout=60
#Seconds for the server response to consider a good connection
connection_answer_time=2
#The Persistent Volume Claim deployment
pvcDeploy="$folder/kubernetes/volumes.yaml"
#The target deployment file
targetDeploy="$folder/kubernetes/deployment.yaml"
#Variable to select connection type, 0=clear, 1=encrypted
enc=0
#Pulseaudio port
pulsePort=34567
#List of supported apps
supported_apps=("firefox" "libreoffice" "blender" "cuda_blender")
#List of supported protocols
supported_protocols=("vnc" "novnc")
#Variable containing the k8s namespace to be used
k8s_namespace="k8s-on-desktop"
#Variable containing the ssh port
ssh_port=22
#Variable to select whether to use pvc or not
use_pvc=0
#The vncviewer pod file
tigervncPodFile="$folder/kubernetes/vncviewer.yaml"
#vncviewer run mode (0-> native app, 1-> docker container, 2-> k8s pod)
supported_run_modes=("0 (native app)" "1 (docker container)" "2 (k8s pod)")
default_run_mode=0
run_mode=$default_run_mode
#TigerVNC viewer docker's name and version
tigervnc_docker="riccardoroccaro/vncviewer:stable"
tigervnc_dockerfile_path="$folder/docker/vncviewer"
tigervnc_container_name="riccardoroccaro-vncviewer"
#TigerVNC viewer pod app name
tigervnc_pod_app_name="riccardoroccaro-vncviewer"

#Set SECURE_CONNECTION to 1/0 depending on encryption
function adjust_encription {
	line=`grep -n 'SECURE_CONNECTION' ${targetDeploy} | cut -d : -f -1`
	((line=line+1))

	sed -i "${line}s/[0-1]/${enc}/" ${targetDeploy}	
}

#Set application name in deployment
function adjust_appname_pid_secret_label {
	sed -i "s/RAR_001_APP_NAME_PID/${vnc_srv_app_pid}/" ${targetDeploy}
	sed -i "s/RAR_002_APP_NAME/${application_name}/" ${targetDeploy}
	sed -i "s/RAR_003_SSH_SECRET/${ssh_secret_name}/" ${targetDeploy}
	sed -i "s#RAR_004_NS_LABEL#${viewer_ns_label}#" ${targetDeploy}
}

#Set the new generated token
function adjust_token {
	line=`grep -n 'VNC_PASSWORD' ${targetDeploy} | cut -d : -f -1`
	((line=line+1))
	
	sed -i "${line}s/\".*\"/\"$token\"/" ${targetDeploy}
}

function adjust_volumes {
	from=`grep -n "RAR_002_APP_NAME-persistent-storage" ${targetDeploy} | cut -d : -f -1`
	((to=from+2))
	sed -i "${from},${to} {s/^#//g}" ${targetDeploy}

	from=`grep -n "${application_name}-persistent-storage" ${targetDeploy} | cut -d : -f -1`
	((to=from+1))
	sed -i "${from},${to} {s/^#//g}" ${targetDeploy}
}

#Remove services and ports depending on protocol used
function adjust_protocol {
	from_novnc_service=`grep -w -n 'novnc-svc-port' ${targetDeploy} | cut -d : -f -1`
	((till_novnc_service=from_novnc_service+3))
	from_vnc_service=`grep -w -n 'vnc-svc-port' ${targetDeploy} | cut -d : -f -1`
	((till_vnc_service=from_vnc_service+3))
	from_novnc_container=`grep -w -n 'novnc-cont-port' ${targetDeploy} | cut -d : -f -1`
	((till_novnc_container=from_novnc_container+1))
	from_vnc_container=`grep -w -n 'vnc-cont-port' ${targetDeploy} | cut -d : -f -1`
	((till_vnc_container=from_vnc_container+1))
	
	if [[ $enc -eq 1 ]]; then
		sed -i "${from_novnc_container},${till_novnc_container}d;${from_novnc_service},${till_novnc_service}d;${from_vnc_container},${till_vnc_container}d;${from_vnc_service},${till_vnc_service}d" ${targetDeploy}
	elif [ "$protocol" = "vnc" ]; then
		sed -i "${from_novnc_container},${till_novnc_container}d;${from_novnc_service},${till_novnc_service}d" ${targetDeploy}
	else 
		sed -i "${from_vnc_container},${till_vnc_container}d;${from_vnc_service},${till_vnc_service}d" ${targetDeploy}
	fi
}

#Function to wait for the Nodeport to be opened
function scan_node_port {
	for i in $(seq $timeout); do
		nc -z $targetNodeIp $targetNodePortSsh
		if [ $? -eq 0 ]; then
			return 0
		fi
	done
	return 1
}

#Retrieving the ip, ports, pod name and namespace
function retrieve_pod_info {
	read -r targetNodeIp targetPodName targetPodNamespace <<<$(kubectl get pod -l app=$vnc_srv_app_pid -n $k8s_namespace -o "jsonpath={..status.hostIP} {.items..metadata.name} {.items..metadata.namespace}")
	if [[ $enc -eq 1 ]]; then
		read -r targetNodePortSsh <<<$(kubectl get svc -l app=$vnc_srv_app_pid -n $k8s_namespace -o 'jsonpath={..spec.ports[?(@.name=="ssh-svc-port")].nodePort}')
	else
		read -r targetNodePortProtocol targetNodePortSsh <<<$(kubectl get svc -l app=$vnc_srv_app_pid -n $k8s_namespace -o 'jsonpath={..spec.ports[?(@.name=="'${protocol}'-svc-port")].nodePort} {..spec.ports[?(@.name=="ssh-svc-port")].nodePort}')
	fi
}

#Function to get the current k8s node info
function retrieve_curr_k8s_node_info {
	#Retrieveing the node_name and node_address
	old_IFS=$IFS
	IFS='#' read -r -a current_node_info <<< $(kubectl get nodes -l kubernetes.io/hostname=`cat /etc/hostname` -o 'jsonpath={range .items[0].status.addresses[*]}{.type}={.address}#{end}')
	for ((i=0; i<${#current_node_info[@]}; i++)); do 
		if [[ $(echo ${current_node_info[$i]} | cut -d '=' -f 1) == "Hostname" ]];then
			current_node_name=$(echo ${current_node_info[$i]} | cut -d '=' -f 2)
		fi
		if [[ $(echo ${current_node_info[$i]} | cut -d '=' -f 1) == "InternalIP" ]];then
			current_node_address=$(echo ${current_node_info[$i]} | cut -d '=' -f 2)
		fi
	done
	IFS=$old_IFS
}

#Function to test namespace existence
function test_ns_existance {
	for ns_token_to_test in $(kubectl get ns | grep $k8s_namespace); do
		if [[ $ns_token_to_test == $k8s_namespace ]]; then
			return 0
		fi
	done
	return 1
}

#Function to prepare the cluster for the cloudify execution
function prepare_cluster {
	echo -n "Check $k8s_namespace namespace existence..."
	#Check namespace existence
	test_ns_existance
	if [[ $? -eq 1 ]]; then
		echo -n "It doesn't exist! => Creating namespace..."
		#Create namespace
		kubectl create ns $k8s_namespace &>/dev/null
		#Check namespace creation
		if [ $? -ne 0 ]; then
			echo "Error: Unable to create the namespace. Running ${application_name} locally"
			clear_and_exit 7
		fi
		echo "OK"
	else
		echo "It exists"
	fi
	
	#Add label to namespace useful to apply resources on liqo.io
	echo -n "Apply liqo.io/enabled=true label to $k8s_namespace namespace..."
	kubectl label ns $k8s_namespace "liqo.io/enabled=true" --overwrite &>/dev/null
	#Check label return conde
	if [ $? -ne 0 ]; then
		echo "Error: Unable to apply label the namespace. Running ${application_name} locally"
		clear_and_exit 8
	fi
	echo "OK"

	#Add label to the current node to avoid vncserver pod scheduling
	if [[ $run_mode -eq 2 ]]; then
		retrieve_curr_k8s_node_info
		echo -n "Apply $viewer_ns_label=true label to the current node ($current_node_name)..."
		kubectl label no $current_node_name "$viewer_ns_label=true" --overwrite &>/dev/null
		#Check label return conde
		if [ $? -ne 0 ]; then
			echo "Error: Unable to apply label the current node. Running ${application_name} locally"
			clear_and_exit 9
		fi
		echo "OK"
	fi
}

#Function to remove the namespace and the labels created in prepare_cluster
function clean_cluster {
	if [[ $run_mode -eq 2 ]]; then
		#Remove node label if exists
		echo -n "Removing $viewer_ns_label label from current node ($current_node_name)..."
		kubectl label no $current_node_name "$viewer_ns_label-" &>/dev/null
		echo "OK"
	fi
}

#Function that runs the native vnc application
function run_native_vncviewver_novnc_application {
	# Forwarding sound
	echo -n "Loading PulseAudio tcp module..."
	pactl load-module module-native-protocol-tcp port=${pulsePort} auth-ip-acl=127.0.0.1 &>/dev/null
	echo "OK"
	((state=state+1))
	#state=3 ; enc=0,1 ; run_mode=0
	echo -n "Creating PulseAudio ssh tunnel..."
	ssh -o UserKnownHostsFile=/dev/null \
		-i "${working_dir}/id_rsa" \
		-oStrictHostKeyChecking=no -f -N \
		-M -S "${working_dir}/ssh_socket:${targetNodePortSsh}" \
		-R ${pulsePort}:localhost:${pulsePort} \
		vncuser@${targetNodeIp} \
		-p ${targetNodePortSsh} &>/dev/null
	echo "OK"
	((state=state+1))
	#state=4 ; enc=0,1 ; run_mode=0

	if [ $enc -eq 1 ]; then
		#Creating ssh tunnel for the protocol
		echo -n "Creating VNC ssh tunnel..."
		ssh -o UserKnownHostsFile=/dev/null \
			-i "${working_dir}/id_rsa" \
			-oStrictHostKeyChecking=no -f -N \
			-S "${working_dir}/ssh_socket:${targetNodePortSsh}" \
			-L ${port}:localhost:${port} \
			vncuser@${targetNodeIp} \
			-p ${targetNodePortSsh} &>/dev/null
		echo "OK"
		((state=state+1))
		#state=5 ; enc=1 ; run_mode=0
	fi

	#Check the protocol and run the corresponding native app
	if [ "$protocol" = "vnc" ]; then
		vncviewer -CompressLevel $compression -QualityLevel $quality $target -passwd <(echo ${token} | vncpasswd -f) 2>/dev/null
	else
		if [ $enc -eq 1 ]; then
			echo -n "Starting encrypted NOVnc connection..."
			url="http://localhost:$port"
		else
			echo -n "Starting clear NOVnc connection..."
			url="http://$targetNodeIp:$targetNodePortProtocol"
		fi
		echo "OK"
		echo ""
		echo "Your token is ${token}, insert it into your browser"
		notify-send -t 10000 -a 'Kubernetes on Desktop' "One time Token" "$token"
		firefox $url &>/dev/null
		pid=`pgrep firefox`
		((timeout=timeout*timeout))
		
		timeout $timeout tail --pid=$pid -f /dev/null
	fi
}

#Function that creates the vncviewer container and launches it
function create_container_and_launch_vncviewer {
	#Remove existing container if any
	docker container rm $tigervnc_container_name &>/dev/null

	#Create the container and run vncviewer
	echo "Running vncviewer docker..."
	docker run -d --name $tigervnc_container_name \
		-v ${working_dir}:/home/vnc/ssh_id_rsa \
		-v /tmp/.X11-unix/:/tmp/.X11-unix/ \
		--device /dev/snd:/dev/snd \
		-v /dev/shm:/dev/shm \
		-v /var/run/dbus:/var/run/dbus \
		-e DISPLAY \
		$tigervnc_docker \
		enc=$1 `#enc` \
		pod=0 `#pod` \
		compression=$2 `#compression` \
		quality=$3 `#quality` \
		target=$4 `#target` \
		token=$5 `#token` \
		target_node_ip=$6 `#targetNodeIp` \
		target_node_port_ssh=$7	`#targetNodePortSsh` \
		enc_port=$8 `#port` \
		&>/dev/null

	#Check docker run exit code to see if a container error occurred
	if [[ $? -ne 0 ]]; then
		echo "Error: can't run the docker container"
		clear_and_exit 3
	fi

	((state=state+1))
	#state=3 ; enc=0,1 ; run_mode=1

	#Wait for the docker to complete its execution
	echo "Wait for the docker to complete its execution..."
	docker wait $tigervnc_container_name &>/dev/null
	echo "Done."
}

#Function to adjust the vncviewer.yaml file and apply the pod to k8s
function adjust_and_apply_pod {
	#For safety let's copy the pod file and modify the temporary one
	cp ${tigervncPodFile} "${working_dir}/vncviewer.yaml"
	tigervncPodFile="${working_dir}/vncviewer.yaml"

	#Get a free tcp port to listen to
	while true; do
		#Generate random port number
		pod_wait_port=$(shuf -i 1025-65535 -n 1)

		read -r pod_port_to_check_local_ip <<< $(nc -zv localhost $pod_wait_port 2>&1)
		read -r pod_port_to_check_localhost <<< $(nc -zv $current_node_address $pod_wait_port 2>&1)
		#Check generated port
		if [[ $( echo $pod_port_to_check_local_ip | grep succeeded) == "" ]] && \
		   [[ $( echo $pod_port_to_check_localhost | grep succeeded) == "" ]]; then
			#It's a free port. OK
			break;
		fi
	done
	
	#Replace the pod parameters with their values
	sed -i "s#RAR_000_APP_NAME_PID#$vnc_cli_app_pid#g" $tigervncPodFile
	sed -i "s#RAR_001_K8S_NODE_NAME#$current_node_name#g" $tigervncPodFile
	sed -i "s#RAR_002_TIGERVNC_CONTAINER_NAME#$vnc_cli_app_pid#g" $tigervncPodFile
	sed -i "s#RAR_003_TIGERVNC_DOCKER#$tigervnc_docker#g" $tigervncPodFile
	sed -i "s#RAR_004_ENC#enc=$enc#g" $tigervncPodFile
	sed -i "s#RAR_005_POD#pod=1#g" $tigervncPodFile
	sed -i "s#RAR_006_COMPRESSION#compression=$compression#g" $tigervncPodFile
	sed -i "s#RAR_007_QUALITY#quality=$quality#g" $tigervncPodFile
	sed -i "s#RAR_008_TARGET#target=$target#g" $tigervncPodFile
	sed -i "s#RAR_009_TOKEN#token=$token#g" $tigervncPodFile
	sed -i "s#RAR_010_TARGET_NODE_IP#target_node_ip=$targetNodeIp#g" $tigervncPodFile
	sed -i "s#RAR_011_TARGET_NODE_PORT_SSH#target_node_port_ssh=$targetNodePortSsh#g" $tigervncPodFile
	sed -i "s#RAR_012_ENC_PORT#enc_port=$port#g" $tigervncPodFile
	sed -i "s#RAR_013_CLIENT_HOST_IP#client_host_ip=$current_node_address#g" $tigervncPodFile
	sed -i "s#RAR_014_CLIENT_HOST_PORT#client_host_port=$pod_wait_port#g" $tigervncPodFile
	sed -i "s#RAR_015_WORKING_DIR#$working_dir#g" $tigervncPodFile

	#Applying the pod to the current node and wait for the process completion
	kubectl apply -f $tigervncPodFile -n $k8s_namespace &>/dev/null && ((state++))
	#state=3 ; enc=0,1 ; run_mode=2

	#Waiting for the pod to start
	echo -n "Waiting for vncviewer pod to start, max ${timeout} seconds..."
	kubectl wait --for=condition=Ready pod -l "app=${vnc_cli_app_pid}" --timeout=${timeout}s -n $k8s_namespace &>/dev/null

	#Check that vncviewer pod is running, otherwise exit
	if [ $? -ne 0 ]; then
		echo "Error: cannot create vncviewer pod."
		clear_and_exit 6
	else
		echo "OK pod running"
	fi

	echo "Waiting for the pod to be completed..."

	pod_finished_can_exit=0
	while [ $pod_finished_can_exit -eq 0 ]; do
		while read line; do
			if [ "$line" == "Close_${token}" ]; then
				pod_finished_can_exit=1
				break
			fi
		done < <(nc -q -1 -l $pod_wait_port)
	done
}

#Function to prepare the environment for run_mode 0-1
function prepare_env_runmode_0_1 {
	echo -n "Retrieving node IP and PORT..."
	retrieve_pod_info
	echo "OK ip -> ${targetNodeIp}, $protocol -> ${targetNodePortProtocol}, ssh -> ${targetNodePortSsh}, podName -> ${targetPodName}, podNs -> ${targetPodNamespace}"

	echo -n "Waiting for the NodePort to be opened..."
	scan_node_port

	if [ $? -ne 0 ]; then
		echo "ERROR Nodeport took too much to be opened, running ${application_name} locally"
		clear_and_exit 4
	fi
	echo "OK port opened"

	#Set port depending on choosed protocol
	if [ $enc -eq 1 ]; then
		if [ "$protocol" = "vnc" ]; then
			port=5900;
		else
			port=5800;
		fi
	fi

	if [ "$protocol" = "vnc" ]; then
		#Check encryption, if yes -> start vnc encrypted connection
		#otherwise -> start normal vnc connection
		if [ $enc -eq 1 ]; then
			echo "Starting encrypted VNC connection..."
			target="localhost::${port}"
		else
			echo "Starting clear VNC connection..."
			target="$targetNodeIp::$targetNodePortProtocol"
		fi
	fi
}

#Function to prepare the environment for run_mode 0-1
function prepare_env_runmode_2 {
	#Vnc port
	port=5900

	#Variable containing the vncserver service URL
	svc_URL=$vnc_srv_app_pid"-service."$k8s_namespace".svc"

	#Building target
	if [ $enc -eq 1 ]; then
		echo "Starting encrypted VNC connection..."
		target="localhost::$port"
	else
		echo "Starting clear VNC connection..."
		target="$svc_URL::$port"
	fi

	#Use the svc URL instead of pod node IP
	targetNodeIp=$svc_URL

	#Use deployment ssh port instad of the nodeport port
	targetNodePortSsh=$ssh_port
}

#Function to connect to target
function connect {
	case $run_mode in
		0)	#Native app (N.B. the protocol could be vnc or novnc)
			prepare_env_runmode_0_1
			run_native_vncviewver_novnc_application
			;;
		1)	#Docker container (N.B. the protocol must be vnc)
			prepare_env_runmode_0_1
			create_container_and_launch_vncviewer ${enc} ${compression} ${quality} ${target} ${token} ${targetNodeIp} ${targetNodePortSsh} ${port}
			;;
		2)	#K8s pod (N.B. the protocol must be vnc)
			prepare_env_runmode_2
			adjust_and_apply_pod ${enc} ${compression} ${quality} ${target} ${token} ${port} ${targetNodeIp} ${targetNodePortSsh}
			echo "Completed."
			;;
		\?)	#Unsupported run_mode
			echo "ERROR: Unsupported run_mode $run_mode"
			clear_and_exit 2
			;;
	esac
	echo "VNC execution completed."
}

#Main function to start the deployment of the desired application
function start_deploy {
	#If run mode is docker => checking whether the docker image already exists or not and in the latter case crate it
	if [ $run_mode -eq 1 ]; then
		docker inspect $tigervnc_docker &>/dev/null
		if [[ $? == 1 ]]; then
			echo -n "The vncviewer image doesn't exist and will be created..."
			tmp_prev_dir=$(pwd)
			cd $tigervnc_dockerfile_path
			docker build -t $tigervnc_docker . &>/dev/null
			if [[ $? != 0 ]]; then
				echo ""
				echo "Error during vncviewer image build, running ${application_name} locally."
				${application_name} &>/dev/null &
				clear_and_exit 1
			fi
			cd $tmp_prev_dir
			echo "Done."
		else
			echo "The vncviewer image already exists"
		fi
	fi

	#For safety let's copy the deployment and modify the temporary one
	working_dir="/tmp/Cloudify/$(date +%F_%H-%M-%S)"
	mkdir -p $working_dir &>/dev/null
	cp ${targetDeploy} "${working_dir}/deployment.yaml"
	targetDeploy="${working_dir}/deployment.yaml"
	
	#Check if pvc is enabled and adjust the volumes in the yaml file
	if [ $use_pvc -eq 1 ]; then
		adjust_volumes
	fi

	adjust_encription
	adjust_appname_pid_secret_label
	adjust_protocol
	
	#Checking connectivity
	#To perform that task, the command `kubectl describe pods` is used (we could use version, but too fast since tight)
	echo -n "Checking connectivity..."
	nettime=`(/usr/bin/time -f "Time:%e" kubectl describe pods) 2>&1 | tail -1 | grep "Time:" | sed "s/^.*://"`

	if [ $? -eq 0 ]; then			
		#Checking network speed availability
		if [[ $(echo "${nettime}<${connection_answer_time}" | bc) -eq 1 ]]; then
			
			echo "OK cluster answered in ${nettime} seconds"
			
			echo -n "Generating token..."
			token=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1)
			echo "OK"

			adjust_token

			#Generating ssh key pair
			echo -n "Generating ssh key pair..."
			ssh-keygen -t rsa -b 4096 -C "${USER}@kubernetes.io" -f "${working_dir}/id_rsa" -N "" &>/dev/null
			echo "OK"

			#Register Ctr+C interrupt
			trap 'clear_and_exit -1' INT TERM KILL EXIT QUIT HUP

			#Preparing the cluster by creating the k8s-on-desktop namespace and 
			#appling the label k8s-on-desktop/viewer-<pid>=true to the current node 
			#to avoid the vncserver pod to be scheduled on current node
			prepare_cluster

			echo -n "Creating ssh secret..."
			kubectl create secret generic $ssh_secret_name --from-file=authorized_keys="${working_dir}/id_rsa.pub" -n $k8s_namespace &>/dev/null && ((state++))
			#state=1 ; enc=0,1 ; run_mode=0,1,2

			if [ $state -gt 0 ]; then
				echo "OK"

				echo -n "Applying deploy..."
				#Apply both the pvc (if use_pvc=1) and the deploy and increment state variable at the end. This way:
				# 1- If there's a 'Ctrl+C' between the two apply we don't run the risk of don't clear the resources already allocated due to the fact that
				#    the state was not incremented yet (if state++ would be done afterwards);
				# 2- We don't run the risk of a wrong exit status check afterwards due to the fact that if the state is incremented after the apply 
				#	 (even if it fails) the $? variable is 0 because ((state++)) doesn't fail;
				# 3- We don't run the risk of clear resources non allocated yet by increment the state before the apply.
				# N.B.: It works because:
				# a- if the second apply fails the state increment will not be done and the resources will not be allocated
				# b- we don't care about the first apply because the pvc will never be deleted
				if [ $use_pvc -eq 1 ]; then
					kubectl apply -f $pvcDeploy -n $k8s_namespace &>/dev/null && kubectl apply -f $targetDeploy -n $k8s_namespace &>/dev/null && ((state++))
				else
					kubectl apply -f $targetDeploy -n $k8s_namespace &>/dev/null && ((state++))
				fi
				#state=2 ; enc=0,1 ; run_mode=0,1,2

				if [ $? -ge 0 ]; then
					echo "OK"

					#Waiting for the pod to start
					echo -n "Waiting for pod to start, max ${timeout}seconds..."
					kubectl wait --for=condition=Ready pod -l "app=${vnc_srv_app_pid}" --timeout=${timeout}s -n $k8s_namespace &>/dev/null
		
					if [ $? -eq 0 ]; then
						echo "OK pod running"
						connect
						return
					else
						echo "ERROR cannot create pod, running ${application_name} locally"
					fi
				else
					echo "ERROR cannot apply deployment, running ${application_name} locally"
				fi
			else
				echo "ERROR cannot create secret, running ${application_name} locally"
			fi
		else
			echo "ERROR cluster answered in ${nettime} seconds (too slow), running ${application_name} locally"
		fi
	else
		echo "ERROR no Internet, running ${application_name} locally"
	fi
	${application_name} &>/dev/null &
}

#Delete only the deployment NOT the volume
function clear_and_exit {
	#Check if an error occurred and run application locally. If $1 is 0 => no errors occurred
	if [ $1 -ne 0 ]; then
		if [ $1 -lt 0 ]; then
			#If $1 is less than 0 it means that a signal has been caught
			echo "Process interrupted with signal. Cleaning up and exiting..."
		else
			#If $1 is more than 0 it means that an error occured
			echo "Running ${application_name} locally"
			${application_name} &>/dev/null &
		fi
	fi

	if [ $state -ge 4 ]; then
		#Stop ssh VNC and/or PulseAudio tunnel
		echo -n "Stopping SSH VNC and/or PulseAudio tunnel..."
		ssh -S "${working_dir}/ssh_socket:${targetNodePortSsh}" -O "exit" vncuser@${targetNodeIp} &>/dev/null
		echo "OK"
	fi

	if [ $state -ge 3 ] && [ $run_mode -eq 2 ]; then
		#Deleteing the pod that was executing vncviewer
		echo -n "Deleting the vncviewer pod..."
		kubectl delete -f $tigervncPodFile -n $k8s_namespace &>/dev/null
		echo "OK"
	fi

	if [ $state -ge 3 ] && [ $run_mode -eq 1 ]; then
		#Deleting the container that was executing vncviewer
		echo -n "Deleting the vncviewer container..."
		docker container rm -f $tigervnc_container_name &>/dev/null
		echo "OK"
	fi

	if [ $state -ge 3 ] && [ $run_mode -eq 0 ]; then
		#Unloading PulseAudio TCP module
		echo -n "Unloading PulseAudio TCP module..."
		pactl unload-module module-native-protocol-tcp &>/dev/null
		echo "OK"
	fi

	if [ $state -ge 2 ]; then
		#Deleting deploy on cluster
		echo -n "Deleting deploy on cluster..."
		kubectl delete -f $targetDeploy -n $k8s_namespace &>/dev/null
		echo "OK"
	fi

	if [ $state -ge 1 ]; then
		#Deleting ssh secret on cluster
		echo -n "Deleting ssh secret on cluster..."
		kubectl delete secret $ssh_secret_name -n $k8s_namespace &>/dev/null
		echo "OK"
	fi

	#Remove node k8s-on-desktop/viewer label
	clean_cluster

	echo "Process completed"
	
	trap - INT TERM KILL EXIT QUIT HUP

	exit $1
}

#Print usage function
function print_usage_and_exit {
	echo "Run application in Cloud using Kubernetes as orchestrator."
	echo "Usage: ./cloudify [-h] [-e] [-t timeout] [-p protocol] [-q quality] [-c compression] [-r runmode] app_name"
	echo "|-> -h: start the helper menu"
	echo "|-> -e: specify that the connection must be encrypted (0/1, default 0 disabled)"
	echo "|-> -t: connection/wait timeout in seconds (positive number, default $timeout)"
	echo "|-> -p: connection protocol to be used (vnc/novnc, default $protocol)"
	echo "|-> -q: specify the quality of the connection (0-9, default $quality)"
	echo "|-> -c: specify the compression of the connection (0-6, default $compression)"
	echo "|-> -v: specify whether to use the pvc or not (0-no/1-yes, default $use_pvc)"
	echo "|-> -r: vncviewer run mode:" 
	echo "|       0-> native app"
	echo "|       1-> docker container" 
	echo "|       2-> k8s pod"
	echo "|       default-> ${supported_run_modes[$default_run_mode]}." 
	echo "|       Warning: this option can't be used if '-p novnc' is set"
	echo "|"
	echo "|->Example: ./cloudify firefox"
	echo "|->Example: ./cloudify -q 7 -t 10 -e firefox"
	echo "|->Example: ./cloudify -q 7 -t 10 -e -r 1 firefox"
	exit $1
}

#Function to check options conflicts
function check_opts_conflicts {
	if [[ $run_mode =~ ^[1-2]$ ]] && [[ $protocol == "novnc" ]]; then
		printf "ERROR: Can't be used 1 or 2 as parameter in -r option when \"novlc\" protocol is set\n\n"
		print_usage_and_exit 1
	fi
}

function main() {
	#Retrieving the name of the application passed as last argument
	for application_name in $@; do :; done
	asd=1
	if [ $# -lt 1 ] || ! ( IFS=$'\n'; echo "${supported_apps[*]}" ) | grep -qFx "$application_name" &>/dev/null; then
		print_usage_and_exit 1
	fi

	#Variable containing random alphanumeric string used as PID
	app_pid=$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 10 | head -n 1)

	#Variable containing the ssh secret name
	ssh_secret_name="rar-ssh-secret-"$app_pid

	#Generating app names
	echo -n "Generating VNC AppName and pid..."
	vnc_srv_app_pid="$application_name-$app_pid"
	vnc_cli_app_pid="$tigervnc_container_name-$app_pid"
	viewer_ns_label="k8s-on-desktop/vncviewer-$app_pid"
	echo "OK"

	while getopts "hec:q:t:p:v:r:" opt; do
		case $opt in
			e)
				enc=1
				echo "Parameter ENCRYPTION...OK activated"
				;;
			t)
				if [[ ! "$OPTARG" =~ ^[0-9]+$ ]]; then
					print_usage_and_exit 1
				fi
				timeout=$OPTARG
				echo "Parameter TIMEOUT...OK ${timeout}"
				;;
			q)
				if [[ ! "$OPTARG" =~ ^[0-9]$ ]]; then
					print_usage_and_exit 1
				fi
				quality=$OPTARG
				echo "Parameter QUALITY...OK ${quality}"
				;;
			c)
				if [[ ! "$OPTARG" =~ ^[0-6]$ ]]; then
					print_usage_and_exit 1
				fi
				compression=$OPTARG
				echo "Parameter COMPRESSION...OK ${compression}"
				;;
			h)
				print_usage_and_exit 0
				;;
			p)
				if ! ( IFS=$'\n'; echo "${supported_protocols[*]}" ) | grep -qFx "$OPTARG" &>/dev/null; then
					print_usage_and_exit 1
				fi
				protocol="$OPTARG"
				echo "Parameter PROTOCOL...OK $OPTARG"
				;;
			v) 
				if [[ ! "$OPTARG" =~ ^[0-1]$ ]]; then
					print_usage_and_exit 1
				fi
				use_pvc=$OPTARG
				echo "Parameter USE PVC...OK ${use_pvc}"
				;;
			r)
				if [[ ! "$OPTARG" =~ ^[0-2]$ ]]; then
					print_usage_and_exit 1
				fi
				run_mode=$OPTARG
				echo "Parameter RUN MODE...OK => Run as ${supported_run_modes[$run_mode]}"
				;;
			\?)
				print_usage_and_exit 1
				;;
		esac
	done

	check_opts_conflicts
	start_deploy
	clear_and_exit 0
}

main $@